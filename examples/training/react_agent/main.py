# -*- coding: utf-8 -*-
"""Example of training a ReAct agent on GSM8K with Trinity-RFT."""
import os
from typing import Dict

from agentscope.tuner import tune, Dataset, WorkflowOutput, JudgeOutput
from agentscope.model import TrinityChatModel
from agentscope.agent import ReActAgent
from agentscope.formatter import OpenAIChatFormatter
from agentscope.message import Msg


async def run_react_agent(
    task: Dict,
    model: TrinityChatModel,
    auxiliary_models: Dict[str, TrinityChatModel],
) -> WorkflowOutput:
    """A simple workflow function using the ReAct agent to solve tasks.

    Args:
        task (Dict): The task to be solved.
        model (TrinityChatModel): The language model to use.
        auxiliary_models (Dict[str, TrinityChatModel]):
            A dictionary of additional chat models available for
            LLM-as-a-Judge. Not used in this workflow.

    Returns:
        float: The reward obtained by solving the task.
    """
    assert (
        len(auxiliary_models) == 0
    ), "No auxiliary models are used in this workflow."

    sys_prompt = (
        "You are an agent specialized in solving math problems with tools. "
        "Please solve the math problem given to you. You can write and "
        "execute Python code to perform calculation or verify your answer. "
        "You should return your final answer within \\boxed{{}}."
    )
    agent = ReActAgent(
        name="react_agent",
        sys_prompt=sys_prompt,
        model=model,
        enable_meta_tool=True,
        formatter=OpenAIChatFormatter(),
    )
    response = await agent.reply(
        msg=Msg("user", task["question"], role="user"),
    )
    return WorkflowOutput(
        response=response,
    )


async def gsm8k_judge(
    task: Dict,
    response: Msg,
    auxiliary_models: Dict[str, TrinityChatModel],
) -> JudgeOutput:
    """A simple judge function to calculate reward based on agent's response.

    Args:
        task (Dict): The task information for the corresponding workflow.
        response (Msg): The response generated by the corresponding workflow.
        auxiliary_models (Dict[str, TrinityChatModel]):
            A dictionary of additional chat models available for LLM-as-a-Judge
            usage. The keys are model names, and the values are the
            corresponding TrinityChatModel instances.

    Returns:
        JudgeOutput: The reward value assigned by the judge function.
    """
    from trinity.common.rewards.math_reward import MathBoxedRewardFn

    assert (
        len(auxiliary_models) == 0
    ), "No auxiliary models are used in this workflow."

    reward_fn = MathBoxedRewardFn()
    # parse truth from gsm8k raw text
    truth = task["answer"]
    if isinstance(truth, str) and "####" in truth:
        truth = truth.split("####")[1].strip()
    else:
        truth = str(truth)
    # parse answer from response message
    result = response.get_text_content()
    reward_dict = reward_fn(
        response=result,
        truth=truth,
    )
    return JudgeOutput(
        reward=sum(reward_dict.values()),
        metrics=reward_dict,
    )


if __name__ == "__main__":
    config_path = os.path.join(
        os.path.dirname(__file__),
        "config.yaml",
    )
    dataset = Dataset(
        path="openai/gsm8k",
        name="main",
        split="train",
    )
    tune(
        workflow_func=run_react_agent,
        judge_func=gsm8k_judge,
        train_dataset=dataset,
        config_path=config_path,
    )
